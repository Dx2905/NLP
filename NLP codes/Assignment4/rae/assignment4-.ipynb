{"cells":[{"cell_type":"markdown","source":["# Assignment 4: Text Classification\n","\n","    Author: Group F - Gaurav, Xiaowen Sun, Jheel Harnish Kamdar, Ruijia Xiong\n","    Created at: 04/09/2024"],"metadata":{"id":"MGdQnewDegJ1"},"id":"MGdQnewDegJ1"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset\n","from tqdm import tqdm\n","import torch\n","from transformers import pipeline\n","from transformers.pipelines.pt_utils import KeyDataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from transformers import pipeline, BartTokenizer, BartForConditionalGeneration\n","from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"Eigq_IUKgqlY"},"id":"Eigq_IUKgqlY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","seed = 9"],"metadata":{"id":"eoWdPlBjgww_"},"id":"eoWdPlBjgww_","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Data Exploration"],"metadata":{"id":"WIvJGFFMfTEJ"},"id":"WIvJGFFMfTEJ"},{"cell_type":"code","source":["train_dataset = load_dataset('yelp_review_full', split='train')\n","test_dataset = load_dataset('yelp_review_full', split='test')\n","print(train_dataset)\n","print(test_dataset)\n","print('Train dataset label values', Counter(train_dataset['label']))\n","print('Test dataset label values', Counter(test_dataset['label']))"],"metadata":{"id":"jqn70c0AedcL"},"id":"jqn70c0AedcL","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","*   The yelp_review dataset has the train datset and the test dataset. Both datasets have two columns: text and label. Both datasets are well-labeled.\n","*    The train dataset has 650,000 rows of data, and the test dataset has 50,000 entities. Both dataset is balanced - each of the 5 classes has same amount of entites.\n","*   **For Our Assignment 4, we'll be using 10,000 rows of data from the test dataset.**\n","\n","\n","\n","\n"],"metadata":{"id":"Dx0CLy6jg11c"},"id":"Dx0CLy6jg11c"},{"cell_type":"code","source":["# dataset = load_dataset('yelp_review_full', split='train[:20%]')\n","dataset = load_dataset('yelp_review_full', split='train').shuffle(seed=seed).select(range(100))\n","df = dataset.to_pandas()\n","print(f'test data frame shape: {df.shape}')"],"metadata":{"id":"vFkuAe07fZwA"},"id":"vFkuAe07fZwA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.label.value_counts())\n","\n","# Visualize the distribution of review ratings\n","plt.figure(figsize=(10, 6))  # Increasing the figure size for better readability\n","sns.countplot(x='label', data=df)\n","plt.title('Distribution of Ratings in Yelp Reviews', fontsize=16)\n","plt.xlabel('Rating', fontsize=14)\n","plt.ylabel('Count', fontsize=14)\n","plt.grid(True)  # Add grid for better readability of the plot\n","plt.show()"],"metadata":{"id":"HEPbWFSjldD2"},"id":"HEPbWFSjldD2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["lens=[len(i.split()) for i in df.text]\n","plt.hist(lens)"],"metadata":{"id":"0FYMbW0tldBR"},"id":"0FYMbW0tldBR","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Sentiment Analysis"],"metadata":{"id":"su5mlUJJfWjB"},"id":"su5mlUJJfWjB"},{"cell_type":"code","source":["df['binary label'] = np.where(df['label'] < 3, 0, 1)"],"metadata":{"id":"hZ9-M-c_lc-Z"},"id":"hZ9-M-c_lc-Z","execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipelines = {\n","    'BERT': pipeline('sentiment-analysis', model='textattack/bert-base-uncased-SST-2', tokenizer='textattack/bert-base-uncased-SST-2', truncation=True, padding=True, device=device),\n","    'BERT2': pipeline('sentiment-analysis', model='textattack/bert-base-uncased-yelp-polarity', tokenizer='textattack/bert-base-uncased-yelp-polarity', truncation=True, padding=True, device=device),\n","    'tuned_BERT': pipeline('sentiment-analysis', model='LiYuan/amazon-review-sentiment-analysis', tokenizer='LiYuan/amazon-review-sentiment-analysis', truncation=True, padding=True, device=device),\n","    'RoBERTa': pipeline('sentiment-analysis', model='textattack/roberta-base-SST-2', tokenizer='textattack/roberta-base-SST-2',  truncation=True, padding=True, device=device),\n","    'DistilBERT': pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english', tokenizer='distilbert-base-uncased-finetuned-sst-2-english', truncation=True, padding=True, device=device)\n","}"],"metadata":{"id":"6xAiFFLRlc7y"},"id":"6xAiFFLRlc7y","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","def sentiment_analysis(example):\n","    bert = pipelines['BERT'](example['text'])[0]['label']\n","    bert2 = pipelines['BERT2'](example['text'])[0]['label']\n","    roberta = pipelines['RoBERTa'](example['text'])[0]['label']\n","    distilbert = pipelines['DistilBERT'](example['text'])[0]['label']\n","    return {'text': example['text'],\n","            'BERT': bert,\n","            'BERT2': bert2,\n","            'RoBERTa': roberta,\n","            'DistilBERT': distilbert}\n","dataset_labels = dataset.map(sentiment_analysis)"],"metadata":{"id":"1z7FOZxhlc59"},"id":"1z7FOZxhlc59","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Convert labels to intergers: 0-Negative, 1-Positive  "],"metadata":{"id":"lXIGVbkFoLuA"},"id":"lXIGVbkFoLuA"},{"cell_type":"code","source":["for col in ['BERT', 'BERT2', 'RoBERTa', 'DistilBERT']:\n","    df[col] = dataset_labels[col]\n","df['BERT'] = df['BERT'].apply(lambda x: int(x[-1]))\n","df['BERT2'] = df['BERT2'].apply(lambda x: int(x[-1]))\n","df['RoBERTa'] = df['RoBERTa'].apply(lambda x: int(x[-1]))\n","df['DistilBERT'] = np.where(df['DistilBERT'] == 'NEGATIVE', 0, 1)"],"metadata":{"id":"ksF5QrRHn_gM"},"id":"ksF5QrRHn_gM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in ['BERT', 'BERT2', 'RoBERTa', 'DistilBERT']:\n","  plt.figure(figsize=(10, 6))\n","  sns.countplot(x=col, data=df)\n","  plt.title('Distribution of Ratings in Yelp Reviews', fontsize=16)\n","  plt.xlabel('Rating', fontsize=14)\n","  plt.ylabel('Count', fontsize=14)\n","  plt.grid(True)\n","  plt.show()"],"metadata":{"id":"moImEHWFouvD"},"id":"moImEHWFouvD","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kdRgTNQUoust"},"id":"kdRgTNQUoust","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hS99nT17ouqm"},"id":"hS99nT17ouqm","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q-jyInZ-ouoH"},"id":"Q-jyInZ-ouoH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the summarized texts\n","for example in dataset_labels.select(50):\n","    print('===============================================================')\n","    print(len(example['text'].split()))\n","    print(\"Original Text:\", example['text'])\n","    print('\\n')\n","    print(f\"bert: {example['BERT']}\")\n","    print(f\"bert2: {example['BERT2']}\")\n","    print(f\"roberta: {example['RoBERTa']}\")\n","    print(f\"distilbert: {example['DistilBERT']}\")"],"metadata":{"id":"_bzD0J2Hlc3Y"},"id":"_bzD0J2Hlc3Y","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sentiment_intensity_analysis():\n","    # Creating a new column for sentiment intensity based on original ratings\n","    df['intensity'] = df['label'].apply(lambda x: 'Low' if x < 2 else 'Medium' if x == 2 else 'High')\n","\n","    # Plotting model performance by sentiment intensity\n","    for model_name in pipelines:\n","        sns.countplot(x=df[model_name], hue=df['intensity'])\n","        plt.title(f'Sentiment Intensity Distribution for {model_name}')\n","        plt.xlabel('Model Prediction')\n","        plt.ylabel('Count')\n","        plt.legend(title='Sentiment Intensity')\n","        plt.show()\n","\n","sentiment_intensity_analysis()"],"metadata":{"id":"6M8Y1DT3lc1B"},"id":"6M8Y1DT3lc1B","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparative accuracy across models by original star ratings\n","def comparative_accuracy_by_rating():\n","    ratings = sorted(df['label'].unique())\n","    accuracies = {model: [] for model in pipelines.keys()}\n","\n","    for rating in ratings:\n","        subset = df[df['label'] == rating]\n","        for model in pipelines.keys():\n","            acc = accuracy_score(subset['binary_label'], subset[model])\n","            accuracies[model].append(acc)\n","\n","    # Plotting\n","    for model, acc_list in accuracies.items():\n","        plt.plot(ratings, acc_list, label=model)\n","\n","    plt.title('Model Accuracy by Original Star Ratings')\n","    plt.xlabel('Star Rating')\n","    plt.ylabel('Accuracy')\n","    plt.xticks(ratings)\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","comparative_accuracy_by_rating()"],"metadata":{"id":"2fC2cPxBlcwL"},"id":"2fC2cPxBlcwL","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"q6zjYUBzlctt"},"id":"q6zjYUBzlctt","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rft06FVolcq2"},"id":"rft06FVolcq2","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rxXVgHfplcni"},"id":"rxXVgHfplcni","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Classification Tasks\n","## 3.a Classification Based on Summaries"],"metadata":{"id":"mrhN7Y1rfWgK"},"id":"mrhN7Y1rfWgK"},{"cell_type":"code","source":[],"metadata":{"id":"kQ80v2yGfaCg"},"id":"kQ80v2yGfaCg","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.b Zero-Shot Classification"],"metadata":{"id":"0DLSOsndfWdn"},"id":"0DLSOsndfWdn"},{"cell_type":"code","source":["def sum_sentiment_analysis(example):\n","    bert = pipelines['BERT'](example['summary'])[0]['label']\n","    bert2 = pipelines['BERT2'](example['summary'])[0]['label']\n","    roberta = pipelines['RoBERTa'](example['summary'])[0]['label']\n","    distilbert = pipelines['DistilBERT'](example['summary'])[0]['label']\n","    return {'summary': example['summary'],\n","            'BERT': bert,\n","            'BERT2': bert2,\n","            'RoBERTa': roberta,\n","            'DistilBERT': distilbert}\n","sum_dataset_labels = dataset_with_summaries.map(sum_sentiment_analysis)\n","for model in ['BERT', 'BERT2', 'RoBERTa', 'DistilBERT']:\n","    col = f'sum_{model}'\n","    df[col] = sum_dataset_labels[col]\n","df['sum_BERT'] = df['sum_BERT'].apply(lambda x: int(x[-1]))\n","df['sum_BERT2'] = df['sum_BERT2'].apply(lambda x: int(x[-1]))\n","df['sum_RoBERTa'] = df['sum_RoBERTa'].apply(lambda x: int(x[-1]))\n","df['sum_DistilBERT'] = np.where(df['sum_DistilBERT'] == 'NEGATIVE', 0, 1)"],"metadata":{"id":"TNs5r6sufq2w"},"id":"TNs5r6sufq2w","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","zero_pipelines = {\n","    'BART':pipeline(task=\"zero-shot-classification\", model = \"facebook/bart-large-mnli\", device=device),\n","    'DeBERTa':pipeline(task=\"zero-shot-classification\", model = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\", tokenizer = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\", device=device),\n","    # sentence transformer: cross encoder\n","    'CrossEncoder': pipeline(task=\"zero-shot-classification\", model = \"cross-encoder/nli-MiniLM2-L6-H768\", tokenizer = \"cross-encoder/nli-MiniLM2-L6-H768\", device=device)}\n","\n","def zero_shot_classification(example, candidate_tags, pipeline):\n","    zeroshot = pipeline(example['text'], candidate_tags)\n","    return {'text': example['text'], 'zeroshot': zeroshot}\n","\n","outcome = defaultdict(list)\n","for name in zero_pipelines:\n","    _ = dataset_100.map(lambda example: zero_shot_classification(example, candidate_tags, zero_pipelines[name]))\n","    for element in _['zeroshot']:\n","        outcome[name].append(element['labels'][0])"],"metadata":{"id":"7vESsTxNJGCq"},"id":"7vESsTxNJGCq","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}