{"cells":[{"cell_type":"code","source":["!pip install datasets > /dev/null 2>&1"],"metadata":{"id":"605Q_MQBx07R","executionInfo":{"status":"ok","timestamp":1713116888550,"user_tz":240,"elapsed":20281,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LdGL32NlxiLP","executionInfo":{"status":"ok","timestamp":1713116905232,"user_tz":240,"elapsed":16686,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset\n","import torch\n","from transformers import pipeline\n","from transformers.pipelines.pt_utils import KeyDataset\n","import time\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGo9xFndxifw","executionInfo":{"status":"ok","timestamp":1713116905232,"user_tz":240,"elapsed":10,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"1a1eaa6e-4500-4188-a90a-e4b7ad2948e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","source":["train_dataset = load_dataset('yelp_review_full', split='train[:1%]')\n","test_dataset = load_dataset('yelp_review_full', split='test[:1%]')\n","print(train_dataset)\n","print(test_dataset)"],"metadata":{"id":"yClNhR5gx4WK","colab":{"base_uri":"https://localhost:8080/","height":440,"referenced_widgets":["7fb69fd6fac140dbb2beaa0350411993","66f7a6c1ce0649a8988b0be602e8e3da","4864b102c5524c3f854c14ba5007efd1","fe9be4b5cb914c20a1f21597fdb0cbb2","3535f00ffa3f4153af31d3a1332996d7","4126e9be6e2b427781c9c324c2069e04","08a0e09c01c543f49c80c0a3b65ce052","361cd214e371440d85fdf1a30f890c48","e1dd88ac01394558a42841afe3f9ad79","867520ead84c42058ae4ead1850fca34","bebff143546b42a588ce7a1b5faed5c7","bb9ac341e8494c59934c29be40b6d3f9","51b3cc648d29486ab077a7ed604f0d67","46b5c5e6af7d43f0b68be40f9d11f5fb","60a8126d44004a78b2eefd4aee1c1f06","41497434b4214d14add95fa613140bdf","f7edc5fcbba245b28ead272cc628a5c9","4bfad59396084142973ed86cc8c38c54","939f350a2ae845b28b5fa66d1b5eb603","ef7a2d853cbf46dd881f1c8bb8c13d75","b45256bb3f97498d900c68e581a0473e","6ee11e26d4ba4b12bf4bc0b613ee82a2","82b3319aebe04bb6ad8ce05c2d4017e4","06c06e88db30407489d5337e2dc957ae","3517ef322567469293bbde93e22ccad4","eacb2b3802424348a75c1c8df94205b0","f22cb84c13c3467084bfe998f30876e8","86759b0d12144cdc97d0d6fac7f4eb46","e9b8019f9b264fb0ae0b2c17f8cc950a","1542f0ed930c4e44a0fa332a802e3eaa","67fb94a516bf44f5a19cfc249d2bcde1","cc620420dc644a37adda930565eccbf4","901a5655a89d4a25841df8e907b6313f","788ff8e4e1a94078abf150d113564c6a","9a445ff0623e44e2af9e3a5a4ce69505","2d39421f1432413183bc13090a8dbdf7","eea22e0ae7ab4fe5add7ae2a3497cf6d","b405085dbf0b44a896100269b3f7d53e","4a50e0a9eb2742efa1212a03a7f87542","154dcdb223bd4142be3355c7f1d3a93a","fabf81d37ef54abea924393e9f1df300","60accc6c52924112870b25c22f9119ed","d4528ce653d04f64926b835a90225fb0","a2f8eca2e4a54b44abd3dd8559d7469e","182de587b8584d33b69c725503af00ab","388c27c14d8b40519c719999099657a2","aca4996b721f45818b60ad79bf407e63","1af605afcaf442d6a6bfe388eb86a788","5e09b45f3e2d459f80627e27ba9e97b9","f46e8ce5b2554455a164a9aee1b99f3e","077d1ed63e814905b6b0d4a4d7dbc550","71b91672d032444a861e0b8aa8a351d1","940cb3481944492b94043e3eb66a4220","c78b4d527adc44ff9abfc16cbd63ce13","f9952871ae0a450e9e52376bd690905f"]},"executionInfo":{"status":"ok","timestamp":1713116941489,"user_tz":240,"elapsed":36264,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"163dd7cc-1d1e-453d-b9a2-68ebf1d47282"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/6.72k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fb69fd6fac140dbb2beaa0350411993"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/299M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb9ac341e8494c59934c29be40b6d3f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82b3319aebe04bb6ad8ce05c2d4017e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"788ff8e4e1a94078abf150d113564c6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182de587b8584d33b69c725503af00ab"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['label', 'text'],\n","    num_rows: 6500\n","})\n","Dataset({\n","    features: ['label', 'text'],\n","    num_rows: 500\n","})\n"]}]},{"cell_type":"code","source":["train_df = train_dataset.to_pandas()\n","test_df = test_dataset.to_pandas()"],"metadata":{"id":"K7L4wnUCuO4q","executionInfo":{"status":"ok","timestamp":1713116941489,"user_tz":240,"elapsed":5,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["len('find you')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pwmvToPuXql","executionInfo":{"status":"ok","timestamp":1713116943764,"user_tz":240,"elapsed":4,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"8c18729a-c5c9-4b48-8c26-0b8d42ab5a83"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"O1aJ_se-uXoq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Bou3RiwUuXlt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X8genI8SuXjT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wdeJ-x8LuXgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8qJMP7IQuXdn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize sentiment analysis pipelines for each selected model\n","pipelines = {\n","    'BERT': pipeline('sentiment-analysis', model='bert-base-uncased', truncation=True, padding=True, device=device),\n","    'RoBERTa': pipeline('sentiment-analysis', model='roberta-base', truncation=True, padding=True, device=device),\n","    'DistilBERT': pipeline('sentiment-analysis', model='distilbert-base-uncased', truncation=True, padding=True, device=device)\n","}"],"metadata":{"id":"cgTP4LIPx50l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = train_dataset.to_pandas()\n","df_test = test_dataset.to_pandas()\n","X_train = df_train['text'].values\n","y_train = df_train['label'].values\n","X_test = df_test['text'].values\n","y_test = df_test['label'].values\n","\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=9)"],"metadata":{"id":"JaQ8kXZmx7IN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# Create a function to tokenize a set of texts\n","def preprocessing_for_bert(data):\n","    \"\"\"Perform required preprocessing steps for pretrained BERT.\n","    @param    data (np.array): Array of texts to be processed.\n","    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n","    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n","                  tokens should be attended to by the model.\n","    \"\"\"\n","    # Create empty lists to store outputs\n","    input_ids = []\n","    attention_masks = []\n","\n","    # For every sentence...\n","    for sent in data:\n","        # `encode_plus` will:\n","        #    (1) Tokenize the sentence\n","        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n","        #    (3) Truncate/Pad sentence to max length\n","        #    (4) Map tokens to their IDs\n","        #    (5) Create attention mask\n","        #    (6) Return a dictionary of outputs\n","        encoded_sent = tokenizer.encode_plus(\n","            text=sent,\n","            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n","            max_length=512,                  # Max length to truncate/pad\n","            pad_to_max_length=True,         # Pad sentence to max length\n","            truncation = True,\n","#             return_tensors='pt',            # Return PyTorch tensor\n","            return_attention_mask=True      # Return attention mask\n","            )\n","\n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_masks.append(encoded_sent.get('attention_mask'))\n","\n","    # Convert lists to tensors\n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","\n","    return input_ids, attention_masks"],"metadata":{"id":"_o8QNehxx91m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concatenate train data and test data\n","all_texts = np.concatenate([df_train.text.values, df_test.text.values])\n","len(all_texts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYVEXquzDP7W","executionInfo":{"status":"ok","timestamp":1713106242382,"user_tz":240,"elapsed":3,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"7ce0cdad-c582-45a9-fbfc-51fd18980467"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7000"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# Encode our concatenated data\n","encoded_texts = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_texts]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsOS6NmhFxci","executionInfo":{"status":"ok","timestamp":1713106309501,"user_tz":240,"elapsed":24271,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"1ced75ce-89cb-46b6-819b-53d08b4d1fdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","source":["# Find the maximum length\n","max_len = max([len(sent) for sent in encoded_texts])\n","print('Max length: ', max_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAJbmxeiFyDV","executionInfo":{"status":"ok","timestamp":1713106326182,"user_tz":240,"elapsed":600,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"747dfce5-39be-42b8-9a59-bd9ef629f243"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max length:  1215\n"]}]},{"cell_type":"code","source":["# # Concatenate train data and test data\n","# all_texts = np.concatenate([df_train.text.values, df_test.text.values])\n","\n","# # Encode our concatenated data\n","# encoded_texts = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_texts]\n","\n","# # Find the maximum length\n","# max_len = max([len(sent) for sent in encoded_texts])\n","# print('Max length: ', max_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTZ4VWVOyAT7","executionInfo":{"status":"ok","timestamp":1713067623218,"user_tz":240,"elapsed":37855,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"7eebad67-3d8a-49c3-bbc3-4f00c47628ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Max length:  1215\n"]}]},{"cell_type":"code","source":["# # Concatenate train data and test data\n","# all_texts = np.concatenate([df_train.text.values, df_test.text.values])\n","\n","# # Encode our concatenated data\n","# encoded_texts = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_texts]\n","\n","# # Find the maximum length\n","# max_len = max([len(sent) for sent in encoded_texts])\n","# print('Max length: ', max_len)"],"metadata":{"id":"8ksKNwoRyJA2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify `MAX_LEN`\n","MAX_LEN = 512\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X_train[0]])[0].squeeze().numpy())\n","attention_masks = list(preprocessing_for_bert([X_train[0]])[1].squeeze().numpy())\n","print('Original: ', X_train[0])\n","print('Token IDs: ', token_ids)\n","print('Attention Masks: ', attention_masks)\n","\n","# # Run function `preprocessing_for_bert` on the train set and the validation set\n","# print('Tokenizing data...')\n","# train_inputs, train_masks = preprocessing_for_bert(X_train)\n","# val_inputs, val_masks = preprocessing_for_bert(X_val)\n","# test_inputs, test_masks = preprocessing_for_bert(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dOQ3qIx9yiWw","executionInfo":{"status":"ok","timestamp":1713106497677,"user_tz":240,"elapsed":725,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"458dc93c-8848-4158-d6a4-cc7b4305d582"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  I don't understand why this place is so popular.  I've been there 4 times and each time the food was pretty gross.  Most recently, I ordered a Del Monico sandwich and the thing was dripping with oil.  The beer list is decent.\n","Token IDs:  [101, 1045, 2123, 1005, 1056, 3305, 2339, 2023, 2173, 2003, 2061, 2759, 1012, 1045, 1005, 2310, 2042, 2045, 1018, 2335, 1998, 2169, 2051, 1996, 2833, 2001, 3492, 7977, 1012, 2087, 3728, 1010, 1045, 3641, 1037, 3972, 12256, 11261, 11642, 1998, 1996, 2518, 2001, 14309, 2007, 3514, 1012, 1996, 5404, 2862, 2003, 11519, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Attention Masks:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train)\n","val_inputs, val_masks = preprocessing_for_bert(X_val)\n","test_inputs, test_masks = preprocessing_for_bert(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HxVShjJGx2j","executionInfo":{"status":"ok","timestamp":1713106585670,"user_tz":240,"elapsed":34112,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"1e755f2e-c670-4588-9fc5-2b4cd7ea7e76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing data...\n"]}]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZtlP4pgG6UU","executionInfo":{"status":"ok","timestamp":1713106589016,"user_tz":240,"elapsed":717,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"c109591d-ff96-4a17-dc57-ca9b09a63a08"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5850,)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["test_masks.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqZMDnkcG-fu","executionInfo":{"status":"ok","timestamp":1713106635300,"user_tz":240,"elapsed":3,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"b882288e-1920-4ff0-f429-e6a5e8765902"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([500, 512])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"SzPUCTHKG-dZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6Uun1VX6G-bL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","test_labels = torch.tensor(y_test)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our test set\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"skMtuP1eyKyK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","# Create the BertClassfier class\n","class BertClassifier(nn.Module):\n","    \"\"\"Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, freeze_bert=False):\n","        \"\"\"\n","        @param    bert: a BertModel object\n","        @param    classifier: a torch.nn.Module classifier\n","        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n","        \"\"\"\n","        super(BertClassifier, self).__init__()\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","        D_in, H, D_out = 768, 50, 5\n","\n","        # Instantiate BERT model\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","        # Instantiate an one-layer feed-forward classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(D_in, H),\n","            nn.ReLU(),\n","            #nn.Dropout(0.5),\n","            nn.Linear(H, D_out)\n","        )\n","\n","        # Freeze the BERT model\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        Feed input to BERT and the classifier to compute logits.\n","        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n","                      max_length)\n","        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n","                      information with shape (batch_size, max_length)\n","        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n","                      num_labels)\n","        \"\"\"\n","        # Feed input to BERT\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)\n","\n","        # Extract the last hidden state of the token `[CLS]` for classification task\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","\n","        # Feed input to classifier to compute logits\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"],"metadata":{"id":"0QSE3563yNJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","def initialize_model(epochs=4):\n","    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n","    \"\"\"\n","    # Instantiate Bert Classifier\n","    bert_classifier = BertClassifier(freeze_bert=False)\n","\n","    # Tell PyTorch to run the model on GPU\n","    bert_classifier.to(device)\n","\n","    # Create the optimizer\n","    optimizer = AdamW(bert_classifier.parameters(),\n","                      lr=5e-5,    # Default learning rate\n","                      eps=1e-8    # Default epsilon value\n","                      )\n","\n","    # Total number of training steps\n","    total_steps = len(train_dataloader) * epochs\n","\n","    # Set up the learning rate scheduler\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0, # Default value\n","                                                num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler"],"metadata":{"id":"idrBOZHmyPyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import time\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.  \"\"\"\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    \"\"\"Train the BertClassifier model.  \"\"\"\n","    # Start training loop\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # ======================================= # Training # =======================================\n","        # Print the header of the result table\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*5)\n","        # Measure the elapsed time of each epoch\n","        t0_epoch, t0_batch = time.time(), time.time()\n","        # Reset tracking variables at the beginning of each epoch\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","        # Put the model into the training mode\n","        model.train()\n","        # For each batch of training data...\n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # Load batch to GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","            # Zero out any previously calculated gradients\n","            model.zero_grad()\n","            # Perform a forward pass. This will return logits.\n","            logits = model(b_input_ids, b_attn_mask)\n","            # Compute loss and accumulate the loss values\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","            # Perform a backward pass to calculate gradients\n","            loss.backward()\n","            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            # Update parameters and the learning rate\n","            optimizer.step()\n","            scheduler.step()\n","            # Print the loss values and time elapsed for every 20 batches\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # Calculate time elapsed for 20 batches\n","                time_elapsed = time.time() - t0_batch\n","                # Print training results\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","                # Reset batch tracking variables\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","        # Calculate the average loss over the entire training data\n","        avg_train_loss = total_loss / len(train_dataloader)\n","        print(\"-\"*7)\n","\n","        # ======================================= # Evaluation # =======================================\n","        if evaluation == True:\n","            # After the completion of each training epoch, measure the model's performance on our validation set.\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","            # Print performance over the entire training data\n","            time_elapsed = time.time() - t0_epoch\n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*9)\n","            print(\"\\n\")\n","    print(\"Training complete!\")\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"After the completion of each training epoch, measure the model's performance  on our validation set.  \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during the test time.\n","    model.eval()\n","    # Tracking variables\n","    val_accuracy = []\n","    val_loss = []\n","    # For each batch in our validation set...\n","    for batch in val_dataloader:\n","      # Load batch to GPU\n","      b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","      # Compute logits\n","      with torch.no_grad():\n","          logits = model(b_input_ids, b_attn_mask)\n","          # Compute loss\n","          loss = loss_fn(logits, b_labels)\n","          val_loss.append(loss.item())\n","          # Get the predictions\n","          preds = torch.argmax(logits, dim=1).flatten()\n","          # Calculate the accuracy rate\n","          accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","          val_accuracy.append(accuracy)\n","    # Compute the average accuracy and loss over the validation set.\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","    return val_loss, val_accuracy"],"metadata":{"id":"MYGC3gjbyR7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(42)\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bx28YCAIyUF3","executionInfo":{"status":"ok","timestamp":1713067815653,"user_tz":240,"elapsed":106778,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"22339b1e-3e7e-476f-f09b-cc17aef2b727"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","-----\n","   1    |   20    |   1.591398   |     -      |     -     |   7.06   \n","   1    |   40    |   1.477198   |     -      |     -     |   5.14   \n","   1    |   60    |   1.377464   |     -      |     -     |   5.16   \n","   1    |   80    |   1.292122   |     -      |     -     |   5.27   \n","   1    |   100   |   1.284891   |     -      |     -     |   5.23   \n","   1    |   120   |   1.256290   |     -      |     -     |   5.27   \n","   1    |   140   |   1.208009   |     -      |     -     |   5.29   \n","   1    |   160   |   1.226272   |     -      |     -     |   5.33   \n","   1    |   180   |   1.225143   |     -      |     -     |   5.39   \n","   1    |   182   |   1.215655   |     -      |     -     |   0.51   \n","-------\n","   1    |    -    |   1.326768   |  1.148785  |   49.61   |   51.41  \n","---------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","-----\n","   2    |   20    |   1.024262   |     -      |     -     |   5.72   \n","   2    |   40    |   1.004612   |     -      |     -     |   5.53   \n","   2    |   60    |   0.962215   |     -      |     -     |   5.58   \n","   2    |   80    |   0.985819   |     -      |     -     |   5.60   \n","   2    |   100   |   1.043208   |     -      |     -     |   5.61   \n","   2    |   120   |   0.942187   |     -      |     -     |   5.63   \n","   2    |   140   |   0.976760   |     -      |     -     |   5.69   \n","   2    |   160   |   1.031235   |     -      |     -     |   5.72   \n","   2    |   180   |   0.997161   |     -      |     -     |   5.75   \n","   2    |   182   |   1.255324   |     -      |     -     |   0.55   \n","-------\n","   2    |    -    |   0.999367   |  1.133949  |   51.85   |   53.26  \n","---------\n","\n","\n","Training complete!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CvJII98lyozg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create empty lists to store outputs\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in ['I love you', 'i hate you']:\n","    print(sent)\n","    # `encode_plus` will:\n","    #    (1) Tokenize the sentence\n","    #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n","    #    (3) Truncate/Pad sentence to max length\n","    #    (4) Map tokens to their IDs\n","    #    (5) Create attention mask\n","    #    (6) Return a dictionary of outputs\n","    encoded_sent = tokenizer.encode_plus(\n","        text=sent,\n","        add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n","        max_length=50,                  # Max length to truncate/pad\n","        pad_to_max_length=True,         # Pad sentence to max length\n","        truncation = True,\n","#             return_tensors='pt',            # Return PyTorch tensor\n","        return_attention_mask=True      # Return attention mask\n","        )\n","\n","    # Add the outputs to the lists\n","    input_ids.append(encoded_sent.get('input_ids'))\n","    attention_masks.append(encoded_sent.get('attention_mask'))\n","\n","# Convert lists to tensors\n","input_ids = torch.tensor(input_ids)\n","attention_masks = torch.tensor(attention_masks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPSyRzmrDUtg","executionInfo":{"status":"ok","timestamp":1713106133628,"user_tz":240,"elapsed":368,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"c8ef9551-74e1-4547-9bc0-2aa08ae5de10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I love you\n","i hate you\n"]}]},{"cell_type":"code","source":["input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctnr-55pDUmf","executionInfo":{"status":"ok","timestamp":1713106142656,"user_tz":240,"elapsed":3,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"bba78f14-fb86-4f39-b488-75aa8b853a59"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 101, 1045, 2293, 2017,  102,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0],\n","        [ 101, 1045, 5223, 2017,  102,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["attention_masks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDhnSzwkDUjq","executionInfo":{"status":"ok","timestamp":1713106165989,"user_tz":240,"elapsed":692,"user":{"displayName":"Rae Xiong","userId":"16332631767867485886"}},"outputId":"43df5d20-0466-4614-8ca9-100d55a0524e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0],\n","        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":[],"metadata":{"id":"pbk2K7xiFZgD"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7fb69fd6fac140dbb2beaa0350411993":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66f7a6c1ce0649a8988b0be602e8e3da","IPY_MODEL_4864b102c5524c3f854c14ba5007efd1","IPY_MODEL_fe9be4b5cb914c20a1f21597fdb0cbb2"],"layout":"IPY_MODEL_3535f00ffa3f4153af31d3a1332996d7"}},"66f7a6c1ce0649a8988b0be602e8e3da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4126e9be6e2b427781c9c324c2069e04","placeholder":"​","style":"IPY_MODEL_08a0e09c01c543f49c80c0a3b65ce052","value":"Downloading readme: 100%"}},"4864b102c5524c3f854c14ba5007efd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_361cd214e371440d85fdf1a30f890c48","max":6724,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1dd88ac01394558a42841afe3f9ad79","value":6724}},"fe9be4b5cb914c20a1f21597fdb0cbb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_867520ead84c42058ae4ead1850fca34","placeholder":"​","style":"IPY_MODEL_bebff143546b42a588ce7a1b5faed5c7","value":" 6.72k/6.72k [00:00&lt;00:00, 414kB/s]"}},"3535f00ffa3f4153af31d3a1332996d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4126e9be6e2b427781c9c324c2069e04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08a0e09c01c543f49c80c0a3b65ce052":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"361cd214e371440d85fdf1a30f890c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1dd88ac01394558a42841afe3f9ad79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"867520ead84c42058ae4ead1850fca34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bebff143546b42a588ce7a1b5faed5c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb9ac341e8494c59934c29be40b6d3f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51b3cc648d29486ab077a7ed604f0d67","IPY_MODEL_46b5c5e6af7d43f0b68be40f9d11f5fb","IPY_MODEL_60a8126d44004a78b2eefd4aee1c1f06"],"layout":"IPY_MODEL_41497434b4214d14add95fa613140bdf"}},"51b3cc648d29486ab077a7ed604f0d67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7edc5fcbba245b28ead272cc628a5c9","placeholder":"​","style":"IPY_MODEL_4bfad59396084142973ed86cc8c38c54","value":"Downloading data: 100%"}},"46b5c5e6af7d43f0b68be40f9d11f5fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_939f350a2ae845b28b5fa66d1b5eb603","max":299436850,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef7a2d853cbf46dd881f1c8bb8c13d75","value":299436850}},"60a8126d44004a78b2eefd4aee1c1f06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b45256bb3f97498d900c68e581a0473e","placeholder":"​","style":"IPY_MODEL_6ee11e26d4ba4b12bf4bc0b613ee82a2","value":" 299M/299M [00:16&lt;00:00, 16.2MB/s]"}},"41497434b4214d14add95fa613140bdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7edc5fcbba245b28ead272cc628a5c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bfad59396084142973ed86cc8c38c54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"939f350a2ae845b28b5fa66d1b5eb603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef7a2d853cbf46dd881f1c8bb8c13d75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b45256bb3f97498d900c68e581a0473e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ee11e26d4ba4b12bf4bc0b613ee82a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82b3319aebe04bb6ad8ce05c2d4017e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06c06e88db30407489d5337e2dc957ae","IPY_MODEL_3517ef322567469293bbde93e22ccad4","IPY_MODEL_eacb2b3802424348a75c1c8df94205b0"],"layout":"IPY_MODEL_f22cb84c13c3467084bfe998f30876e8"}},"06c06e88db30407489d5337e2dc957ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86759b0d12144cdc97d0d6fac7f4eb46","placeholder":"​","style":"IPY_MODEL_e9b8019f9b264fb0ae0b2c17f8cc950a","value":"Downloading data: 100%"}},"3517ef322567469293bbde93e22ccad4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1542f0ed930c4e44a0fa332a802e3eaa","max":23515519,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67fb94a516bf44f5a19cfc249d2bcde1","value":23515519}},"eacb2b3802424348a75c1c8df94205b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc620420dc644a37adda930565eccbf4","placeholder":"​","style":"IPY_MODEL_901a5655a89d4a25841df8e907b6313f","value":" 23.5M/23.5M [00:01&lt;00:00, 18.1MB/s]"}},"f22cb84c13c3467084bfe998f30876e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86759b0d12144cdc97d0d6fac7f4eb46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b8019f9b264fb0ae0b2c17f8cc950a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1542f0ed930c4e44a0fa332a802e3eaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67fb94a516bf44f5a19cfc249d2bcde1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc620420dc644a37adda930565eccbf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901a5655a89d4a25841df8e907b6313f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"788ff8e4e1a94078abf150d113564c6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a445ff0623e44e2af9e3a5a4ce69505","IPY_MODEL_2d39421f1432413183bc13090a8dbdf7","IPY_MODEL_eea22e0ae7ab4fe5add7ae2a3497cf6d"],"layout":"IPY_MODEL_b405085dbf0b44a896100269b3f7d53e"}},"9a445ff0623e44e2af9e3a5a4ce69505":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a50e0a9eb2742efa1212a03a7f87542","placeholder":"​","style":"IPY_MODEL_154dcdb223bd4142be3355c7f1d3a93a","value":"Generating train split: 100%"}},"2d39421f1432413183bc13090a8dbdf7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fabf81d37ef54abea924393e9f1df300","max":650000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60accc6c52924112870b25c22f9119ed","value":650000}},"eea22e0ae7ab4fe5add7ae2a3497cf6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4528ce653d04f64926b835a90225fb0","placeholder":"​","style":"IPY_MODEL_a2f8eca2e4a54b44abd3dd8559d7469e","value":" 650000/650000 [00:05&lt;00:00, 112138.06 examples/s]"}},"b405085dbf0b44a896100269b3f7d53e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a50e0a9eb2742efa1212a03a7f87542":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"154dcdb223bd4142be3355c7f1d3a93a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fabf81d37ef54abea924393e9f1df300":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60accc6c52924112870b25c22f9119ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4528ce653d04f64926b835a90225fb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2f8eca2e4a54b44abd3dd8559d7469e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"182de587b8584d33b69c725503af00ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_388c27c14d8b40519c719999099657a2","IPY_MODEL_aca4996b721f45818b60ad79bf407e63","IPY_MODEL_1af605afcaf442d6a6bfe388eb86a788"],"layout":"IPY_MODEL_5e09b45f3e2d459f80627e27ba9e97b9"}},"388c27c14d8b40519c719999099657a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f46e8ce5b2554455a164a9aee1b99f3e","placeholder":"​","style":"IPY_MODEL_077d1ed63e814905b6b0d4a4d7dbc550","value":"Generating test split: 100%"}},"aca4996b721f45818b60ad79bf407e63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71b91672d032444a861e0b8aa8a351d1","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_940cb3481944492b94043e3eb66a4220","value":50000}},"1af605afcaf442d6a6bfe388eb86a788":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c78b4d527adc44ff9abfc16cbd63ce13","placeholder":"​","style":"IPY_MODEL_f9952871ae0a450e9e52376bd690905f","value":" 50000/50000 [00:00&lt;00:00, 102855.00 examples/s]"}},"5e09b45f3e2d459f80627e27ba9e97b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f46e8ce5b2554455a164a9aee1b99f3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"077d1ed63e814905b6b0d4a4d7dbc550":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71b91672d032444a861e0b8aa8a351d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"940cb3481944492b94043e3eb66a4220":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c78b4d527adc44ff9abfc16cbd63ce13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9952871ae0a450e9e52376bd690905f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}