{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209527, 8)\n"
     ]
    }
   ],
   "source": [
    "# Assuming the dataset is in a CSV file\n",
    "dataset_path = '/Users/jheelkamdar/Downloads/CS6120/A2/News_Category_Dataset_v3.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.shape)\n",
    "\n",
    "# Handle missing values\n",
    "df = df.fillna('')  # Replace NaN with an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after removing special characters and lowercasing:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    over  million americans roll up sleeves for om...\n",
       "1    american airlines flyer charged banned for lif...\n",
       "2     of the funniest tweets about cats and dogs th...\n",
       "3    the funniest tweets from parents this week sep...\n",
       "4    woman who called cops on black birdwatcher los...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove special characters and apply lowercasing\n",
    "df['cleaned_text'] = df.apply(lambda row: re.sub(r'[^a-zA-Z\\s]', '', row['headline'] + ' ' + row['short_description']).lower(), axis=1)\n",
    "# Display data after removing special characters and lowercasing\n",
    "print(\"\\nData after removing special characters and lowercasing:\")\n",
    "df['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after removing stopwords:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    million americans roll sleeves omicrontargeted...\n",
       "1    american airlines flyer charged banned life pu...\n",
       "2    funniest tweets cats dogs week sept dog dont u...\n",
       "3    funniest tweets parents week sept accidentally...\n",
       "4    woman called cops black birdwatcher loses laws...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda text: ' '.join([word for word in word_tokenize(text) if word not in stop_words]))\n",
    "\n",
    "# Display data after removing stopwords\n",
    "print(\"\\nData after removing stopwords:\")\n",
    "df['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
