{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb2735ef-8ce6-4ebd-b9d2-9faed622b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e035c5fc-fccc-49cb-b936-1bbd15a1feb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   pn_num  case_num                                         pn_history\n",
      "0       0         0  17-year-old male, has come to the student heal...\n",
      "1       1         0  17 yo male with recurrent palpitations for the...\n",
      "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
      "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
      "4       4         0  17yo male with no pmh here for evaluation of p...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jheelkamdar/Downloads/CS6120/A1/patient_notes.csv')\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6868fe3b-1023-447c-8cb3-4813ccb43333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Case Conversion:\n",
      "0    17-year-old male, has come to the student heal...\n",
      "1    17 yo male with recurrent palpitations for the...\n",
      "2    dillon cleveland is a 17 y.o. male patient wit...\n",
      "3    a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
      "4    17yo male with no pmh here for evaluation of p...\n",
      "Name: pn_history, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['pn_history'] = df['pn_history'].str.lower()\n",
    "print(\"After Case Conversion:\")\n",
    "print(df['pn_history'].head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fec72140-a6a5-4470-985a-34edd7d690cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Removing Punctuation:\n",
      "0    17yearold male has come to the student health ...\n",
      "1    17 yo male with recurrent palpitations for the...\n",
      "2    dillon cleveland is a 17 yo male patient with ...\n",
      "3    a 17 yo m co palpitation started 3 mos ago \\r\\...\n",
      "4    17yo male with no pmh here for evaluation of p...\n",
      "Name: pn_history, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['pn_history'] = df['pn_history'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n",
    " \n",
    "\n",
    "print(\"After Removing Punctuation:\")\n",
    "print(df['pn_history'].head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09b3c2b9-def5-4bda-813e-93db2a10f37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.04101991653442383 seconds\n",
      "0        17yearold male has come to the student health ...\n",
      "1        17 yo male with recurrent palpitations for the...\n",
      "2        dillon cleveland is a 17 yo male patient with ...\n",
      "3        a 17 yo m co palpitation started 3 mos ago \\r\\...\n",
      "4        17yo male with no pmh here for evaluation of p...\n",
      "                               ...                        \n",
      "42141    ms madden is a 20 yo female presenting w the w...\n",
      "42142    a 20 yo f came complain a dull 810 headache th...\n",
      "42143    ms madden is a 20yo female who presents with a...\n",
      "42144    stephanie madden is a 20 year old woman compla...\n",
      "42145    patient is a 20 yo f who presents with a heada...\n",
      "Name: pn_history, Length: 42146, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import time\n",
    "\n",
    "# Load the pre-built dictionary\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=5, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "# Function for correcting spelling in a text\n",
    "def correct_spelling(text):\n",
    "    suggestions = sym_spell.lookup(text, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "    corrected_text = suggestions[0].term if suggestions else text\n",
    "    return corrected_text\n",
    "\n",
    "# Assuming df['pn_history'] contains your physician notes\n",
    "start_time = time.time()\n",
    "df['pn_history'] = df['pn_history'].apply(correct_spelling)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "# Print the corrected dataframe\n",
    "print(df['pn_history'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7af30501-edb3-4ccb-a90f-b0f8a0832f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Standardizing Formats:\n",
      "0    17yearold male has come to the student health ...\n",
      "1    17 yo male with recurrent palpitations for the...\n",
      "2    dillon cleveland is a 17 yo male patient with ...\n",
      "3    a 17 yo m co palpitation started 3 mos ago \\r\\...\n",
      "4    17yo male with no pmh here for evaluation of p...\n",
      "Name: pn_history, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['pn_history'] = df['pn_history'].str.replace(r'(\\d{2})-(\\d{2})-(\\d{4})', 'date_placeholder')\n",
    "\n",
    "df['pn_history'] = df['pn_history'].str.replace(r'\\b\\d+\\b', 'number_placeholder')\n",
    "\n",
    "df['pn_history'] = df['pn_history'].str.replace(r'\\$\\s?\\d+(\\.\\d{2})?', 'currency_placeholder')\n",
    "print(\"After Standardizing Formats:\")\n",
    "print(df['pn_history'].head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66bd5b50-a99b-4bda-b08c-cee372f12095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17yearold male has come to the student health ...\n",
      "1    17 year old male with recurrent palpitations f...\n",
      "2    dillon cleveland is a 17 year old male patient...\n",
      "3    a 17 year old m complaint of palpitation start...\n",
      "4    17yo male with no past medical history here fo...\n",
      "Name: pn_history, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary of common contractions and their expansions\n",
    "contractions_dict = {\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"yo\": \"year old\", \n",
    "    \"y/o\": \"year old\",\n",
    "    \"yearold\": \"year old\",\n",
    "    \"mo\": \"month old\",\n",
    "    \"m/o\": \"month old\",\n",
    "    \"bp\": \"blood pressure\",\n",
    "    \"c/o\": \"complaint of\",\n",
    "    \"co\": \"complaint of\",\n",
    "    \"pmh\" : \"past medical history\",\n",
    "    \"psh\" : \"past surgical history\"\n",
    "}\n",
    "\n",
    "# Function to replace contractions using regex\n",
    "def replace_contractions(text):\n",
    "    for contraction, expansion in contractions_dict.items():\n",
    "        text = re.sub(fr'\\b{contraction}\\b', expansion, text)\n",
    "    return text\n",
    "\n",
    "# Apply the contractions replacement function to the 'physician_notes' column\n",
    "df['pn_history'] = df['pn_history'].apply(replace_contractions)\n",
    "print(df['pn_history'].head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06518d6c-f05a-41d1-aad2-ae278b7b2b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17yearold male has come to the student health ...\n",
      "1    17 year old male with recurrent palpitations f...\n",
      "2    dillon cleveland is a 17 year old male patient...\n",
      "3    a 17 year old m complaint of palpitation start...\n",
      "4    17yo male with no past medical history here fo...\n",
      "Name: pn_history, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_gender_in_age(text):\n",
    "    # Define a regex pattern to identify \"m\" or \"f\" before \"year old\"\n",
    "    pattern = re.compile(r'\\b([mf])\\s+year\\s+old\\b', re.IGNORECASE)\n",
    "    # Replace \"m\" with \"male\" and \"f\" with \"female\"\n",
    "    updated_text = re.sub(pattern, lambda match: 'male' if match.group(1).lower() == 'm' else 'female', text)\n",
    "    return updated_text\n",
    "\n",
    "df['pn_history'] = df['pn_history'].apply(replace_gender_in_age)\n",
    "print(df['pn_history'].head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "437b7bc9-0617-4c45-9584-fa16e9cfb093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42146, 64575)\n",
      "Number of features: 64575\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>004am</th>\n",
       "      <th>00h</th>\n",
       "      <th>01</th>\n",
       "      <th>010</th>\n",
       "      <th>010510</th>\n",
       "      <th>011</th>\n",
       "      <th>0110</th>\n",
       "      <th>...</th>\n",
       "      <th>zeromonth</th>\n",
       "      <th>zexually</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>ziminopril</th>\n",
       "      <th>zno</th>\n",
       "      <th>zolpidem</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zopidem</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  004am  00h  01  010  010510  011  0110  ...  zeromonth  \\\n",
       "0   0    0     0      0    0   0    0       0    0     0  ...          0   \n",
       "1   0    0     0      0    0   0    0       0    0     0  ...          0   \n",
       "2   0    0     0      0    0   0    0       0    0     0  ...          0   \n",
       "3   0    0     0      0    0   0    0       0    0     0  ...          0   \n",
       "4   0    0     0      0    0   0    0       0    0     0  ...          0   \n",
       "\n",
       "   zexually  zigzag  ziminopril  zno  zolpidem  zone  zones  zopidem  zzz  \n",
       "0         0       0           0    0         0     0      0        0    0  \n",
       "1         0       0           0    0         0     0      0        0    0  \n",
       "2         0       0           0    0         0     0      0        0    0  \n",
       "3         0       0           0    0         0     0      0        0    0  \n",
       "4         0       0           0    0         0     0      0        0    0  \n",
       "\n",
       "[5 rows x 64575 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "pn_history_vector = vectorizer.fit_transform(df['pn_history'])\n",
    "print(pn_history_vector.shape)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Number of features:\", len(feature_names))\n",
    "\n",
    "pn_history_df = pd.DataFrame(pn_history_vector.toarray(), columns=feature_names)\n",
    "pn_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "313914f1-1ab5-44aa-ab2b-afdddd0cf7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jheelkamdar/miniconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Initialize stemmer and lemmatizer\n",
    "# ---------------------------------------\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'\\W|\\d', ' ', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Apply stemming and lemmatization\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "\n",
    "# ---------------------------------------\n",
    "# Apply customized tokenizer\n",
    "# ---------------------------------------\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "pn_history_vector = vectorizer.fit_transform(df['pn_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b26587d-706f-4a7c-9bed-705c6e900ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jheelkamdar/miniconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'el', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'le', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'plea', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'u', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few ORIGINAL words: ['00' '000' '0000' '004am' '00h' '01' '010' '010510' '011' '0110' '0115lb'\n",
      " '0151' '01ppd' '02' '0202' '03' '03000400' '0311' '0319' '04' '040'\n",
      " '0400' '041' '04c' '04cage' '04currently' '04denies' '04h00' '04no'\n",
      " '04sa' '04sexually' '04than' '04tobsince' '04use' '05' '051' '0510'\n",
      " '0510ppd' '0515' '051hr' '051pach' '051pack' '051packday' '051packet'\n",
      " '051packs' '051packsday' '051pcks' '051pday' '051pk' '051pkday' '051ppd'\n",
      " '051ppd15' '051ppd15yo' '051ppd20' '051ppd20y' '051ppd20yr' '051ppd20yrs'\n",
      " '051ppdday' '051ppdx' '051ppdx20' '051ppdx20years' '051ppdx20yrs'\n",
      " '051ppf' '052' '052pkd' '052ppd' '0531' '054' '05h00' '05ppd'\n",
      " '05ppdx20yrs' '05to' '05x20yrs' '06' '06092017' '061317' '07' '075' '08'\n",
      " '0827' '09' '0930' '0at' '0cage' '0ccup' '0ct' '0f' '0g0p' '0monogamous'\n",
      " '0nce' '0ppd' '0r' '0s' '0sex' '0tobacc0' '0usually' '10' '100' '1000'\n",
      " '1000f']\n",
      "---------\n",
      "First few words after new stop list: ['aa' 'aabdomen' 'aabov' 'aaccompani' 'aaccord' 'aach' 'aactiv' 'aad'\n",
      " 'aadministr' 'aaf' 'aafter' 'aaggrav' 'aaggriv' 'aago' 'aagrav' 'aal'\n",
      " 'aaleiv' 'aalerg' 'aalev' 'aallergi' 'aam' 'aand' 'aanhdonia' 'aani'\n",
      " 'aanywher' 'aao' 'aap' 'aapetit' 'aappendectomi' 'aappetit' 'aaround'\n",
      " 'aasleep' 'aasoc' 'aassocait' 'aasthma' 'aat' 'aattack' 'aauditori'\n",
      " 'aaverag' 'aaw' 'aaway' 'ab' 'abadomin' 'abail' 'abait' 'abaout' 'abaov'\n",
      " 'abaselin' 'abat' 'abbort' 'abbov' 'abc' 'abck' 'abd' 'abdchest'\n",
      " 'abdchestback' 'abdd' 'abddomin' 'abdjoint' 'abdl' 'abdmin' 'abdmoen'\n",
      " 'abdmoin' 'abdmoni' 'abdmonin' 'abdn' 'abdneckachefeverurinari' 'abdnom'\n",
      " 'abdnomin' 'abdnomr' 'abdnorm' 'abdnv' 'abdo' 'abdoback' 'abdoem'\n",
      " 'abdoimin' 'abdoin' 'abdoinla' 'abdom' 'abdomain' 'abdomainl' 'abdoman'\n",
      " 'abdomein' 'abdomeinlalpainchest' 'abdomeit' 'abdomenburninggnawinmg'\n",
      " 'abdomenchest' 'abdomenepigastr' 'abdomenepigastrium' 'abdomeni'\n",
      " 'abdomenit' 'abdomenpelvi' 'abdomenpt' 'abdoment' 'abdomi' 'abdomiala'\n",
      " 'abdomian' 'abdomianl' 'abdomina' 'abdominak']\n"
     ]
    }
   ],
   "source": [
    "stopwords = CountVectorizer(stop_words='english').get_stop_words()\n",
    "len(stopwords)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Adding words to the stop words list \n",
    "# (Note the choice of additional stop words is only for illustration)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "nstopwords = list(stopwords) + ['abdomin', 'abdomen', 'abdonmin','age']\n",
    "print(len(stopwords))\n",
    "print(len(nstopwords))\n",
    "\n",
    "# -------------------------------------------------------- \n",
    "# repeating the process with the new list of stopwords\n",
    "# -------------------------------------------------------- \n",
    "\n",
    "vectorizer2 = CountVectorizer(tokenizer=custom_tokenizer, stop_words=nstopwords)\n",
    "\n",
    "\n",
    "# Fit and transform the 'pn_history' column\n",
    "pn_history_vector = vectorizer2.fit_transform(df['pn_history'])\n",
    "\n",
    "# Get the feature names (tokens)\n",
    "feature_names2 = vectorizer2.get_feature_names_out()\n",
    "\n",
    "\n",
    "print(\"First few ORIGINAL words:\", feature_names[0:100])\n",
    "\n",
    "print(\"---------\")\n",
    "\n",
    "print(\"First few words after new stop list:\", feature_names2[0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb821c54-f1e7-49b4-8bce-7ef07e23a48c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jheelkamdar/miniconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/jheelkamdar/miniconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'el', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'le', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'plea', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'u', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42146, 50271)\n",
      "Number of features: 50271\n",
      "['aa' 'aabdomen' 'aabov' ... 'zone' 'zopidem' 'zzz']\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, stop_words=nstopwords)\n",
    "\n",
    "# Fit and transform the 'pn_history' column\n",
    "pn_history_vector = vectorizer.fit_transform(df['pn_history'])\n",
    "\n",
    "# Print the shape of the vectorized 'pn_history' column\n",
    "print(pn_history_vector.shape)\n",
    "\n",
    "# Get the feature names (tokens)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the number of features (tokens)\n",
    "print(\"Number of features:\", len(feature_names))\n",
    "\n",
    "# Print the first 100 features\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c3307-319e-47b1-9af5-5581cb1f88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, stop_words=nstopwords, use_idf=False)\n",
    "\n",
    "# Fit and transform the 'pn_history' column\n",
    "pn_history_vector_count = vectorizer.fit_transform(df['pn_history'])\n",
    "\n",
    "# Get the feature names (tokens)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create DTM with columns as tokens and rows as documents\n",
    "pn_history_df_count = pd.DataFrame(pn_history_vector_count.toarray(), columns=feature_names)\n",
    "pn_history_df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6faf3d-7e7c-4f28-92b2-50779210aa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
